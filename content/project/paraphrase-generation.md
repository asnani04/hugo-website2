+++
# Date this page was created.
date = "2016-04-27"

# Project title.
title = "Paraphrase Generation Using Deep Generative Models"

# Project summary to display on homepage.
summary = "A Paraphrase generation model that uses control variables in the latent space of a variational autoencoder to determine length of the generated sentence."

# Optional image to display on homepage (relative to `static/img/` folder).
image_preview = "paraphrase_model.png"

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "optimization", "natural-language-processing", "text-generation"]`
tags = ["machine-learning", "paraphrase", "natural-language-processing", "text-generation"]

# Optional external URL for project (replaces project detail page).
external_link = "https://drive.google.com/file/d/1LeQ0cy8mY-NGF-0pv5j2gKuQ56IZX9QL/view?usp=sharing"

# Does the project detail page use math formatting?
math = false

# Optional featured image (relative to `static/img/` folder).
[header]
image = "paraphrase_model.png"
caption = "My caption :smile:"

+++

Among the most enticing things about natural language is the fact that it can be written and spoken in myriad ways. The act of paraphrasing, or saying something that has the same meaning as the original, but in a slightly different manner, has a plethora of possible applications, for e.g. sentence simplification, complication, reporting, vocabulary modulation, tone regulation. We provide a novel deep generative model for paraphrase generation using a variational auto-encoder. We also suggest a method for controlled paraphrase generation using pre-fixed latent variables. We obtain promising results on machine translation & paraphrase evaluation metrics and some interesting correlations in human evaluation. Our results are qualitatively and quantitatively comparable. We also report the current issues with paraphrase evaluation methods, and analyze the popular datasets in that respect.